Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job stats:
job            count
-----------  -------
reads_unzip        1
total              1

Select jobs to execute...

[Mon Jan 15 17:23:35 2024]
rule reads_unzip:
    output: raw_data/reads/reads-3.fastq
    jobid: 0
    reason: Missing output files: raw_data/reads/reads-3.fastq
    wildcards: sample=reads, n=3
    resources: tmpdir=/tmp

bzip2 -vcfdk raw_data/reads/Primary_polyp_AZK_3_ATTCCTTT_L002_R1_001.fastq.bz2 > raw_data/reads/raw_data/reads/reads-3.fastq
[Mon Jan 15 17:23:35 2024]
Error in rule reads_unzip:
    jobid: 0
    output: raw_data/reads/reads-3.fastq
    shell:
        bzip2 -vcfdk raw_data/reads/Primary_polyp_AZK_3_ATTCCTTT_L002_R1_001.fastq.bz2 > raw_data/reads/raw_data/reads/reads-3.fastq
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-01-15T172335.540901.snakemake.log
